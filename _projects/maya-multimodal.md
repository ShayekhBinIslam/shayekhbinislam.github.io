---
layout: page
title: "Maya: Multimodal Aya"
description:  Curating a new multilingual image-text dataset and training Aya/SigLIP models with that data.
# img: assets/img/7.jpg
# redirect: https://unsplash.com
importance: 3
category: "Expedition Aya, Cohere For AI"
---


We develop an open-source multi-modal multi-lingual LLM that possesses both text and image capabilities
in multiple languages (now eight).

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/maya_goals.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>


<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/maya_llava_guard.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/maya_chrf.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

