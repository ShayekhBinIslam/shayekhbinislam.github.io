---
layout: page
title: Evaluating Multilingual Reward Models
description: Developing a multilingual evaluation framework for diverse reward models with appropriate metrics, datasets and baselines.
# img: assets/img/12.jpg # for page background
importance: 1
category: Expedition Aya, Cohere For AI
related_publications: false
# permalink: 
# redirect_to: https://m-rewardbench.github.io/
---
[Project website](https://m-rewardbench.github.io/)

RewardBench is the only established benchmark available that directly evaluates RM capabilities. Even so, RewardBench primarily focuses on English, and does not capture multilingual capabilities.

To address this gap, we translated RewardBench on 23 languages (same set as Aya-23). Our evaluation covers diverse model families, sizes and versions.

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/rm_mult_leaderboard.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>


